"use strict";(self.webpackChunkns_compose_docs=self.webpackChunkns_compose_docs||[]).push([[78],{3905:(e,t,a)=>{a.d(t,{Zo:()=>p,kt:()=>h});var r=a(7294);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function s(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,r,n=function(e,t){if(null==e)return{};var a,r,n={},o=Object.keys(e);for(r=0;r<o.length;r++)a=o[r],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)a=o[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var l=r.createContext({}),u=function(e){var t=r.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):s(s({},t),e)),a},p=function(e){var t=u(e.components);return r.createElement(l.Provider,{value:t},e.children)},c="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},d=r.forwardRef((function(e,t){var a=e.components,n=e.mdxType,o=e.originalType,l=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),c=u(a),d=n,h=c["".concat(l,".").concat(d)]||c[d]||m[d]||o;return a?r.createElement(h,s(s({ref:t},p),{},{components:a})):r.createElement(h,s({ref:t},p))}));function h(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var o=a.length,s=new Array(o);s[0]=d;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i[c]="string"==typeof e?e:n,s[1]=i;for(var u=2;u<o;u++)s[u]=a[u];return r.createElement.apply(null,s)}return r.createElement.apply(null,a)}d.displayName="MDXCreateElement"},9206:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>m,frontMatter:()=>o,metadata:()=>i,toc:()=>u});var r=a(7462),n=(a(7294),a(3905));const o={sidebar_label:"Ecosystem",sidebar_position:2},s="A Unified Ecosystem for fMRI Meta-Analysis",i={unversionedId:"introduction/ecosystem",id:"introduction/ecosystem",title:"A Unified Ecosystem for fMRI Meta-Analysis",description:"Neurosynth Compose is part of a broader set of tools for neuroimaging meta-analysis, with distinct but complementary roles.",source:"@site/docs/introduction/ecosystem.md",sourceDirName:"introduction",slug:"/introduction/ecosystem",permalink:"/compose-docs/introduction/ecosystem",draft:!1,editUrl:"https://github.com/neurostuff/compose-docs/edit/master/docs/introduction/ecosystem.md",tags:[],version:"current",lastUpdatedBy:"Alejandro de la Vega",lastUpdatedAt:1677792385,formattedLastUpdatedAt:"Mar 2, 2023",sidebarPosition:2,frontMatter:{sidebar_label:"Ecosystem",sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"About Compose",permalink:"/compose-docs/"},next:{title:"FAQ",permalink:"/compose-docs/introduction/faq"}},l={},u=[{value:"Neurosynth Compose",id:"neurosynth-compose",level:2},{value:"NeuroStore",id:"neurostore",level:2},{value:"NiMARE",id:"nimare",level:2},{value:"NeuroQuery",id:"neuroquery",level:2},{value:"NIMADS",id:"nimads",level:2},{value:"NeuroVault",id:"neurovault",level:2},{value:"PyMARE",id:"pymare",level:2}],p={toc:u},c="wrapper";function m(e){let{components:t,...a}=e;return(0,n.kt)(c,(0,r.Z)({},p,a,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"a-unified-ecosystem-for-fmri-meta-analysis"},"A Unified Ecosystem for fMRI Meta-Analysis"),(0,n.kt)("p",null,(0,n.kt)("em",{parentName:"p"},"Neurosynth Compose")," is part of a broader set of tools for neuroimaging meta-analysis, with distinct but complementary roles."),(0,n.kt)("h2",{id:"neurosynth-compose"},"Neurosynth Compose"),(0,n.kt)("p",null,"Neurosynth-Compose is the evolution of the original ",(0,n.kt)("a",{parentName:"p",href:"https://neurosynth.org"},"Neurosynth")," project."),(0,n.kt)("p",null,"In ",(0,n.kt)("em",{parentName:"p"},"Neurosynth 1.0"),", we developed a web platform for users to browse a large set of pre-computed meta-analyses\nsynthesizing findings across 14,000+ fMRI studies. The philosophy was to leverage\nlarge scale meta-analysis to provide new insights into the literature, overcoming limitations of database\nwith sheer scale. With regular updates, Neurosynth was able to keep up with the growth of the literature.\nThe database was released with a permissive license, and accompanied by aa Python package to manipulate and analyze it. "),(0,n.kt)("p",null,"Although this approach was surprsingly successful, there were several major limitations to Neurosynth 1.0:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Meta-analyses were limited by ",(0,n.kt)("strong",{parentName:"p"},"concepts that can be inferred from large scale text mining")," (i.e. frequency of terms in the text).\nAlthough these features proved to be surprsingly useful for well-powered and broad cognitive constructs (e.g. 'emotion'), Neurosynth was not able\nto capture the fine-grained details of the neuroimaging literature, or allow users to define their own grouping of studies. ")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"The database is not curated, and therefore contains many ",(0,n.kt)("strong",{parentName:"p"},"inaccuracies and incomplete")," data at both the study and coordinate level.\nAside from obvious extraction erors, automated coordinate extraction lacks the ability to determine critical information, such as whether the activation is positive or negative.\nIn addition, it's not possible to segregate the coordinates into distinct contrast, conditions, or studies without manual curation.")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Coordinate-based analyses are inherently ",(0,n.kt)("strong",{parentName:"p"},"inferior to image-based")," meta-analysis, which is becoming increasingly possible with sharing of unthresholded statisical maps in repositories like ","[NeuroVault][https://neurovault.org]","."))),(0,n.kt)("p",null,(0,n.kt)("em",{parentName:"p"},"Neurosynth Compose")," aims to address these limitations:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Provides a web-based platform for meta-analytic neuroimaging research, allowing users to ",(0,n.kt)("strong",{parentName:"p"},"curate studies"),", and ",(0,n.kt)("strong",{parentName:"p"},"specify meta-analytic models"),". ")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},(0,n.kt)("strong",{parentName:"p"},"Flexible and easy to use"),", allowing users to perform both large-scale ",(0,n.kt)("strong",{parentName:"p"},"exploratory")," meta-analyses, as well as ",(0,n.kt)("strong",{parentName:"p"},"targeted, hypothesis-driven")," meta-analyses that conform to stringent standards such as the ","[PRISMA][https://prisma-statement.org]"," statement.")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Allows users to perfom ",(0,n.kt)("strong",{parentName:"p"},"image-based meta-analysis")," using unthresholded images from NeuroVault (in progress).")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Quick, reproducible and transparent ",(0,n.kt)("strong",{parentName:"p"},"sharing of results"),".")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Incentivizes ",(0,n.kt)("strong",{parentName:"p"},"collaborative curation")," of neuroimaging studies in a accesible ",(0,n.kt)("strong",{parentName:"p"},"centralized repository")," (NeuroStore, see below)."))),(0,n.kt)("h2",{id:"neurostore"},"NeuroStore"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://github.com/neurostuff/neurostore"},"NeuroStore")," will act as a centralized repository for coordinates and maps from neuroimaging studies, stored in NIMADS format."),(0,n.kt)("p",null,"In addition to the database, NeuroStore will provide an API for programmatic querying, as well as a web service with which users\ncan contribute to the database."),(0,n.kt)("p",null,"This repository will version control study information so that users may curate the database,\ncorrecting any mistakes in study data or metadata (such as incorrectly-extracted coordinates).\nThis database curation functionality will fulfill a similar role within the ecosystem to ",(0,n.kt)("a",{parentName:"p",href:"http://brainspell.org/"},"brainspell"),"."),(0,n.kt)("p",null,"NeuroStore will automatically index statistical maps from NeuroVault and ingest newly-extracted coordinates from databases like NeuroQuery."),(0,n.kt)("h2",{id:"nimare"},"NiMARE"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://nimare.readthedocs.io/en/latest/"},"NiMARE")," is a Python package for performing meta-analyses, and derivative analyses using meta-analytic data,\nof the neuroimaging literature.\nWhile meta-analytic packages exist which implement one or two algorithms each,\nNiMARE provides a standard syntax for performing a wide range of analyses and for interacting with databases of coordinates and images\nfrom fMRI studies (e.g., brainspell, Neurosynth, and NeuroVault)."),(0,n.kt)("p",null,"NiMARE joins a growing Python ecosystem for neuroimaging research, which includes such tools as ",(0,n.kt)("a",{parentName:"p",href:"https://nipype.readthedocs.io/en/latest/index.html"},"Nipype"),", ",(0,n.kt)("a",{parentName:"p",href:"https://nistats.github.io/"},"Nistats"),", and ",(0,n.kt)("a",{parentName:"p",href:"https://nilearn.github.io/"},"Nilearn"),".\nAs with these other tools, NiMARE is open source, collaboratively developed, and built with ease of use in mind."),(0,n.kt)("p",null,"NiMARE aims to fill a gap in a burgeoning meta-analytic ecosystem.\nThe goal of NiMARE is to collect a wide range of meta-analytic tools in one Python library.\nCurrently, those methods are spread out across a range of programming languages and user interfaces,\nor are never even translated from the original papers into useable tools.\nNiMARE operates on NIMADS-format datasets, which users will be able to compile by searching the NeuroStore database with the pyNIMADS library.\nA number of other services in the ecosystem will then use NiMARE functions to perform meta-analyses, including Neurosynth 2.0 and ",(0,n.kt)("a",{parentName:"p",href:"https://neurovault.org/"},"NeuroVault"),"."),(0,n.kt)("h2",{id:"neuroquery"},"NeuroQuery"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://neuroquery.org"},"NeuroQuery")," is a web service, Python library, and coordinate database built for large-scale, predictive meta-analysis.\nPredictive meta-analysis generates non-statistical brain maps from text, using a database of coordinates and associated texts."),(0,n.kt)("p",null,"Because the ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/neuroquery/neuroquery_data"},"NeuroQuery database")," is more advanced and accurate than the existing Neurosynth 1.0 database,\nthis new database will effectively replace the old one within the meta-analytic ecosystem.\nNiMARE can ingest the NeuroQuery database and convert it automatically to a NiMARE Dataset object for analysis.\nAdditionally, the NeuroQuery database will feed directly into NeuroStore as a source of coordinates."),(0,n.kt)("p",null,"NeuroQuery-generated predictive meta-analyses will be exportable directly to NeuroVault."),(0,n.kt)("h2",{id:"nimads"},"NIMADS"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://github.com/neurostuff/NIMADS"},"NIMADS")," is a new standard for organizing and representing meta-analytic neuroimaging data.\nNIMADS will be used by NeuroStore, pyNIMADS, and NiMARE."),(0,n.kt)("h2",{id:"neurovault"},"NeuroVault"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://neurovault.org/"},"NeuroVault")," is a database for unthresholded images.\nUsers may upload individual maps or ",(0,n.kt)("a",{parentName:"p",href:"http://nidm.nidash.org/specs/nidm-results_130.html"},"NIDM Results")," packs, which can be exported from a number of fMRI analysis tools,\nlike ",(0,n.kt)("a",{parentName:"p",href:"https://afni.nimh.nih.gov"},"AFNI"),", ",(0,n.kt)("a",{parentName:"p",href:"https://www.fil.ion.ucl.ac.uk/spm/"},"SPM"),", ",(0,n.kt)("a",{parentName:"p",href:"https://fsl.fmrib.ox.ac.uk"},"FSL"),", and ",(0,n.kt)("a",{parentName:"p",href:"https://alpha.neuroscout.org"},"NeuroScout"),"."),(0,n.kt)("p",null,"NeuroVault also has integrations with ",(0,n.kt)("a",{parentName:"p",href:"http://neuropowertools.org"},"NeuroPower")," (for power analyses) and ",(0,n.kt)("a",{parentName:"p",href:"http://neurosynth.org/"},"Neurosynth 1.0")," (for functional decoding),\nand supports simple image-based meta-analyses using NiMARE."),(0,n.kt)("p",null,"Additionally, as the ecosystem is built, users will be able to export meta-analysis results from Neurosynth 2.0 or NiMARE,\nas well as predictive meta-analyses from NeuroQuery, directly to NeuroVault."),(0,n.kt)("h2",{id:"pymare"},"PyMARE"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://pymare.readthedocs.io/en/latest/"},"PyMARE")," is a Python library for effect-size meta-analysis.\nNiMARE uses PyMARE for its image-based meta-analysis algorithms\n(with some light wrapping to convert image objects to arrays compatible with PyMARE functions)."))}m.isMDXComponent=!0}}]);